{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import RNN, LSTM, Dense, BatchNormalization, Dropout, Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>die hard dad army fan nothing ever change got ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  grew b watching loving thunderbird mate school...      0\n",
       "1  put movie dvd player sat coke chip expectation...      0\n",
       "2  people know particular time past like feel nee...      0\n",
       "3  even though great interest biblical movie bore...      0\n",
       "4  die hard dad army fan nothing ever change got ...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('label',axis = 1),df['label'],test_size=0.25,stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = pad_sequences(tokenizer.texts_to_sequences(X_train['text']),maxlen=200)\n",
    "X_test_tokens = pad_sequences(tokenizer.texts_to_sequences(X_test['text']),maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sum([x for _,x in tokenizer.word_counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 50)           177541900 \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,562,151\n",
      "Trainable params: 177,562,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, input_length = 200, output_dim = 50))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 315s 1s/step - loss: 0.4134 - accuracy: 0.8241 - val_loss: 0.2928 - val_accuracy: 0.8789\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 313s 1s/step - loss: 0.1770 - accuracy: 0.9362 - val_loss: 0.2874 - val_accuracy: 0.8942\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 312s 1s/step - loss: 0.0999 - accuracy: 0.9686 - val_loss: 0.3265 - val_accuracy: 0.8844\n",
      "Epoch 3: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d089deb310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode = 'max',patience = 1,verbose = 1)\n",
    "model.fit(X_train_tokens,y_train, validation_data= (X_test_tokens,y_test), batch_size=128,epochs=5,callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tokenizer,open('tokenizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n",
    "tokenizer = pickle.load(open('tokenizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(review):\n",
    "    tokenized_review = pad_sequences(tokenizer.texts_to_sequences([review]),maxlen=200)\n",
    "    prediction = model.predict(tokenized_review,verbose = 0)[0][0]\n",
    "    if prediction>0.5:\n",
    "        print('positive')\n",
    "    else:\n",
    "        print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"Detective Batman at its peak! Great storyline. \n",
    "Just as dark a universe as we've come to expect from DC. The gloomy, gritty, dark tone of this film is exactly what I wanted.\n",
    "When you think the movie is over, there's more. Beautiful cinematography. Great score.\"\"\"\n",
    "\n",
    "predict_review(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"Look at the profiles for the writers that wrote Madame Web. You'll see virtually every movie they've written has a bad rating and bad reviews. Why then does Hollywood continually hire these same writers for these big budget films? I could understand if they wrote movies for Asylum Films because all their movies are terrible.\n",
    "\n",
    "Madame Web is god awful! Very difficult to sit through. None of the main characters are likeable. Even the villain is lame. It seems like the entire movie was written to set up a sequel. But why would people spend money to see the sequel of a movie that is one of the worst movies ever written? I'm shocked at how bad this movie is and if there is a sequel I certainly wont bother watching it.\n",
    "\n",
    "Stop hiring bad writers, Hollywood!\"\"\"\n",
    "\n",
    "predict_review(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
